# Design a Distributed Stream Processing System like Kafka

讓我們先來看看最初在LinkedIn激發Kafka誕生的核心問題。這個問題看似簡單：LinkedIn當時從多個服務中獲取大量日誌資料，包括日誌訊息、指標數據、事件資料，以及其他監控/可觀測性數據。他們希望以兩種方式利用這些資料：

- 建立能即時處理和分析這些資料的線上近即時系統
- 建立能長期處理這些資料的離線系統

多數處理都是為了分析目的，例如分析用戶行為、用戶如何使用LinkedIn等。

這是相當常見的問題，若未曾接觸過，可以舉一個簡單的應用場景：推薦系統驅動。當用戶在LinkedIn搜索某間公司時，廣告引擎應該能即時捕捉這個行為，並在廣告中近即時地向用戶推薦該公司的職缺。而離線系統則可能利用這個資訊，在該公司發布職缺時寄送電子郵件通知用戶。此外，分析團隊還能藉此了解用戶如何搜索公司，以及如何透過LinkedIn平台求職。

問題本身容易理解，但解決方案可能顯得相當複雜。這是由於該問題本身具有多重限制條件和需求，例如：

- 高度可擴展性：熱門產品每天可能產生數十TB甚至數百TB的事件、指標和日誌資料！這需要近乎線性擴展的分散式系統來處理如此高的吞吐量
- 極高流量支援：需輕鬆處理每秒數十萬條訊息。事實上，LinkedIn在2015年的技術部落格就提到每秒約1300萬條訊息的處理量！單一節點根本無法應付，系統必須是分散式架構
- 生產者-消費者模式：需允許「生產者」發送訊息，並讓「消費者」訂閱特定訊息。這點至關重要，因為同一條訊息可能有多個消費者（如我們討論的線上/離線系統），且訊息傳遞通常是非同步的
- 消費自主性：消費者應能自主決定如何及何時消費訊息。例如在討論的案例中，我們需要一個消費者立即處理訊息，另一個則每隔幾小時批量處理
- 簡化設計：訊息具有不可變性（畢竟日誌資料無需刪除），不需要交易式語義或複雜的傳遞保證機制

簡而言之：這是一個超高吞吐量的訊息傳輸系統，重點在於將海量資料從生產者端傳遞到多個消費者端，不需要追求極速傳輸，也無需複雜機制或交易功能，只需最簡潔的方式實現大規模資料傳輸。

## Functional Requirements

- 數據收集與傳輸
  - 支援日誌、指標、事件等多類型數據格式（JSON/Protobuf/Plain Text）
  - 允許分散式生產者（Producers）跨地域/服務推送數據
  - 單叢集處理能力：每日TB級數據（目標：每秒百萬級訊息）
  - 線性擴展架構，可透過增加節點提升吞吐量
- 訊息傳遞模型
  - Pub-Sub模式
  - 生產者與消費者解耦，允許多消費者群組獨立訂閱相同數據流
    - 即時消費者（Online）：近即時處理（如廣告推薦引擎）
    - 離線消費者（Offline）：批次處理（如每日用戶行為分析
- 數據處理與分析
  - 消費節奏自主性
    - 即時消費者：觸發式處理（如事件驅動架構）
    - 離線消費者：窗口式批次拉取（如每小時同步至Hadoop）
  - 位移管理（Offset Control）
    - 消費者可自主重置讀取位置（如重播歷史數據）
    - 支援自動提交（At-least-once）與手動提交（Exactly-once）語義
- 訊息儲存
  - 系統必須能夠儲存大量的訊息數據。
  - 訊息數據可以是不可變的（Immutable）。
    - 寫入後禁止修改/刪除，確保數據稽核軌跡
    - 基於timestamp的訊息順序性保證
  - 訊息數據的儲存不需要複雜的交易語意。
- 高吞吐量與可擴展性
  - 系統必須支援極高的吞吐量（例如：每秒數十萬至數百萬條訊息）。
  - 系統必須具有高度的可擴展性，能夠處理每日數十至數百TB的數據。
  - 系統必須是分布式系統。
- 系統必須支援非同步訊息處理

## Non-functional Requirements

## Core Entities

- Topics:

  每個 Topic 都被分割成一個或多個Partition。每個分區都是一個有序且不可變的訊息序列。Producers將訊息發布到特定的 Topic，而Consumers則訂閱他們感興趣的Topic，以接收這些訊息。

- Broker:

  擁有那些"Queues"的服務器(不論物理或虛擬)，一個Broker可以管理多個partitions。

- Partition:

  Queue本體。Kafka中訊息儲存的基本單位。每個分區都是一個有序且不可變的訊息序列，以日誌檔案形式(log file)存在。它們基本上是只追加（append-only）的系統，用來存儲訊息。可以將分區看作是日誌檔案（log file），而每條訊息則像是該日誌檔案中的一行（line）。

- Producers:

  針對Topic寫入messages/records，指定一個主題（Topic）、一則訊息、一個可選的鍵（Key）和可選的元數據（Metadata），然後將其發送到Broker。

- Consumers (Consumer groups):

  針對Topic讀取messages/records，它會持續向Broker輪詢關於該主題上的任何訊息。在每次輪詢請求中，消費者會指定它最後接收到的訊息以及其他一些可配置的參數。消費者通常會是消費者群組（Consumer Group）的一部分。一般來說，不是單一消費者監聽一個主題（Topic），而是消費者群組監聽主題。消費者群組由多個消費者組成，與 RabbitMQ 不同，Kafka 的消費者群組允許多個消費者共享一個 Topic，但同一條訊息只會被其中一個消費者處理。

## API or System Interface

## High Level Design

## Deep Dives

- 為什麼訊息代理（Message Brokers）不適用?
  如果你熟悉訊息代理（Message Brokers，如 RabbitMQ、ActiveMQ 等），你可能會認為它們能夠解決這個問題。但實際上，它們並不適用。讓我們以 RabbitMQ 為例，來看看它為何無法滿足需求。

  - Message Batching

    在高吞吐量系統中，消費者一次性拉取多條訊息（批次處理）比逐條拉取更有效率。否則，大部分時間會浪費在網路請求上。然而，大多數訊息代理並非為超高吞吐量設計，因此它們通常不提供良好的批次處理機制。

  - Different consumers with different consumption requirements
    先前的介紹中提到，系統有兩種類型的消費者：

    - 線上系統 需要即時處理訊息
    - 離線系統 可能會處理過去 12 到 24 小時 內的訊息

    這種模式與大多數訊息代理（如 RabbitMQ）不兼容，因為 RabbitMQ 採用推送（push-based）模式，會將訊息立即推送給消費者，而消費者無法決定何時消費訊息。此外，RabbitMQ 的佇列並不適合長時間存儲大量訊息，因為其設計並非針對超大佇列，當佇列變大時，效能會嚴重下降。由於缺乏對消費者的彈性支持（例如批次處理、歷史訊息消費等），再加上主要依賴推送機制，因此很難滿足我們的需求。

  - Small, simple messages
    大多數訊息代理的訊息大小較大，這並非錯誤，而是它們的設計使然。例如：

    - 提供複雜的訊息路由選項
    - 訊息可靠性保證（Message Guarantees）
    - 每條訊息的個別確認機制（Acknowledge per message）

    這些功能導致訊息標頭變得很大。如果訊息數量不多、也不需要存儲，那麼這沒問題。但我們的系統需要高吞吐量並持久化存儲大量訊息，這與典型的訊息代理不符。

  - Distributed high-throughput system

    我們的系統需要支持每秒數十萬甚至數百萬條訊息，單節點無法承受這種負載，因此必須是分散式架構。雖然 RabbitMQ 確實支持分散式叢集（Cluster），但其效能遠低於 Kafka，因為 RabbitMQ 並非為超大規模系統設計。

  - Large Queues

    不同的訊息代理（Message Brokers）對於大規模佇列的支援程度不一，這取決於所使用的訊息代理及其配置。然而，網路上有許多開發者反映訊息代理的佇列大小限制帶來的問題。這是因為大多數訊息代理的設計理念是快速處理和傳遞訊息，而不是長時間存儲大量訊息。當佇列變大時，系統可能會遇到效能下降、延遲增加，甚至訊息丟失的問題。這使得訊息代理無法滿足我們對於高吞吐量和持久化存儲的需求。

## 資料來源：

- [medium](https://medium.com/better-programming/system-design-series-apache-kafka-from-10-000-feet-9c95af56f18d)
- [youtube](https://www.youtube.com/watch?v=DU8o-OTeoCc)
